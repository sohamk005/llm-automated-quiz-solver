# utils.py
import os
import json
import httpx
import asyncio
import subprocess
import pandas as pd
from openai import OpenAI
from playwright.async_api import async_playwright
from urllib.parse import urljoin

# Setup LLM Client (Adjust base_url if using the course proxy)
token = os.environ.get("AIPROXY_TOKEN")
client = OpenAI(
    base_url="https://aiproxy.sanand.workers.dev/openai/v1", # Course Proxy URL
    api_key=token
)

async def scrape_task(url):
    """Scrapes the question and logic from the page."""
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        await page.goto(url)
        # Wait for the content to render
        await page.wait_for_selector("body")
        content = await page.content()
        
        # Simple extraction (The LLM will do the heavy lifting of parsing)
        visible_text = await page.evaluate("document.body.innerText")
        await browser.close()
        return visible_text

def llm_solve(task_text):
    """
    Asks the LLM to analyze the question and write Python code to solve it.
    """
    system_prompt = """
    You are an intelligent data extraction and analysis agent. 
    You will receive a raw text dump of a quiz page.
    Your job is to:
    1. Identify the Question.
    2. Identify the Data Source (links to CSVs, tables on page, etc.).
    3. Write a PYTHON SCRIPT that downloads the data, processes it, and prints the final answer.
    4. The script must define a variable `final_answer` containing the result.
    
    IMPORTANT: Return ONLY the python code in a markdown block ```python ... ```.
    Do not add explanations. 
    """
    
    response = client.chat.completions.create(
        model="gpt-4o-mini", # Use a capable model
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"Here is the page text:\n{task_text}"}
        ]
    )
    
    content = response.choices[0].message.content
    # Extract code block
    if "```python" in content:
        code = content.split("```python")[1].split("```")[0].strip()
        return code
    return content

def execute_generated_code(code):
    """
    Executes the code generated by LLM to get the answer.
    WARNING: Executing AI code is risky in production, but necessary for this specific academic project.
    """
    local_vars = {}
    try:
        exec(code, globals(), local_vars)
        return local_vars.get('final_answer')
    except Exception as e:
        print(f"Code Execution Error: {e}")
        return None

async def run_quiz_process(email, secret, current_url):
    """
    The main loop: Scrape -> Solve -> Submit -> Check for Next URL
    """
    max_loops = 5 # Safety break
    loop_count = 0
    
    while current_url and loop_count < max_loops:
        print(f"Processing: {current_url}")
        loop_count += 1
        
        # Step 1: Scrape
        try:
            page_text = await scrape_task(current_url)
        except Exception as e:
            print(f"Scraping failed: {e}")
            break

        # Step 2: Extract Submission URL (usually standard, but safer to ask LLM or regex)
        # We assume the submission URL is derived or listed. For now, we scrape.
        # Let's assume the LLM logic extracts the answer, we need the submit endpoint.
        # Usually in this course, submit URL is [https://example.com/submit](https://example.com/submit) or parsed from text.
        
        # Let's refine the LLM prompt to get the answer DIRECTLY if simple, 
        # or Code if complex. For this specific project, code execution is safer for data tasks.
        
        generated_code = llm_solve(page_text)
        answer = execute_generated_code(generated_code)
        
        if answer is None:
            print("Failed to derive answer.")
            break
            
        print(f"Derived Answer: {answer}")

        # Step 3: Submit
        # NOTE: The submission URL is usually found in the text like "Post your answer to..."
        # We need to extract that URL.
        submit_url_extraction = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": f"Extract the submission URL (starting with https) from this text: {page_text}. Return ONLY the URL."}]
        )
        submit_url = submit_url_extraction.choices[0].message.content.strip()

        payload = {
            "email": email,
            "secret": secret,
            "url": current_url,
            "answer": answer
        }

        async with httpx.AsyncClient() as client_http:
            print(f"Submitting to {submit_url}...")
            resp = await client_http.post(submit_url, json=payload, timeout=10)
            result = resp.json()
            print(f"Submission Result: {result}")

            # Step 4: Check for Chain
            if result.get("correct"):
                next_url = result.get("url")
                if next_url:
                    current_url = next_url
                else:
                    print("Quiz Completed!")
                    break
            else:
                print("Answer incorrect. Retrying or Stopping.")
                # You could add logic here to retry with a different model if wrong
                break