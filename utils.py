# utils.py
import os
import json
import httpx
import asyncio
import subprocess
import pandas as pd
from openai import OpenAI
from playwright.async_api import async_playwright
from urllib.parse import urljoin

# Setup LLM Client (Adjust base_url if using the course proxy)
token = os.environ.get("AIPROXY_TOKEN")
client = OpenAI(
    base_url="https://aipipe.org/openrouter/v1",
    api_key=token
)

async def scrape_task(url):
    """Scrapes the question and logic from the page."""
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        await page.goto(url)
        # Wait for the content to render
        await page.wait_for_selector("body")
        content = await page.content()
        
        # Simple extraction (The LLM will do the heavy lifting of parsing)
        visible_text = await page.evaluate("document.body.innerText")
        await browser.close()
        return visible_text

def llm_solve(task_text):
    """
    Asks the LLM to analyze the question and write Python code to solve it.
    """
    system_prompt = """
    You are an intelligent data extraction and analysis agent. 
    You will receive a raw text dump of a quiz page.
    Your job is to:
    1. Identify the Question.
    2. Identify the Data Source (links to CSVs, tables on page, etc.).
    3. Write a PYTHON SCRIPT that downloads the data, processes it, and prints the final answer.
    4. The script must define a variable `final_answer` containing the result.
    5. IMPORTANT: Do NOT use 'requests.post' to submit the answer in your code. Just calculate the value.
    
    IMPORTANT: Return ONLY the python code in a markdown block ```python ... ```.
    Do not add explanations. 
    """
    
    response = client.chat.completions.create(
        model="gpt-4o-mini", # Use a capable model
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"Here is the page text:\n{task_text}"}
        ]
    )
    
    content = response.choices[0].message.content
    # Extract code block
    if "```python" in content:
        code = content.split("```python")[1].split("```")[0].strip()
        return code
    return content

def execute_generated_code(code):
    """
    Executes the code generated by LLM to get the answer.
    WARNING: Executing AI code is risky in production, but necessary for this specific academic project.
    """
    local_vars = {}
    try:
        exec(code, globals(), local_vars)
        return local_vars.get('final_answer')
    except Exception as e:
        print(f"Code Execution Error: {e}")
        return None

def llm_extract_submit_url(task_text):
    """Asks the LLM to find the submission URL in the text."""
    # Force fallback to the standard submit URL if the LLM gets confused
    system_prompt = """
    Extract the submission URL (starting with https) from the text.
    It usually ends in '/submit'.
    If you cannot find a clear submission URL in the text, return exactly:
    [https://tds-llm-analysis.s-anand.net/submit](https://tds-llm-analysis.s-anand.net/submit)
    Return ONLY the URL.
    """
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": task_text}
        ]
    )
    return response.choices[0].message.content.strip()

async def run_quiz_process(email, secret, current_url):
    """
    The main loop: Scrape -> Solve -> Submit -> Check for Next URL
    """
    max_loops = 5 # Safety break
    loop_count = 0
    
    while current_url and loop_count < max_loops:
        print(f"Processing: {current_url}")
        loop_count += 1
        
        # Step 1: Scrape
        try:
            page_text = await scrape_task(current_url)
        except Exception as e:
            print(f"Scraping failed: {e}")
            break

        # Step 2: Solve
        generated_code = llm_solve(page_text)
        answer = execute_generated_code(generated_code)
        
        if answer is None:
            print("Failed to derive answer.")
            break
            
        print(f"Derived Answer: {answer}")

        # Step 3: Get Submit URL (With Fallback Logic)
        submit_url = llm_extract_submit_url(page_text)

        payload = {
            "email": email,
            "secret": secret,
            "url": current_url,
            "answer": answer
        }

        async with httpx.AsyncClient() as client_http:
            print(f"Submitting to {submit_url}...")
            try:
                # Increased timeout to 30s
                resp = await client_http.post(submit_url, json=payload, timeout=30)
                
                # CRASH PROOFING: Check if response is valid JSON
                try:
                    result = resp.json()
                    print(f"Submission Result: {result}")
                    
                    # Step 4: Check for Chain
                    if result.get("correct"):
                        next_url = result.get("url")
                        if next_url:
                            current_url = next_url
                        else:
                            print("Quiz Completed!")
                            break
                    else:
                        print("Answer incorrect. Retrying or Stopping.")
                        break
                except Exception:
                    print(f"ERROR: Server returned non-JSON response (Likely wrong URL): {resp.text[:200]}")
                    break
                    
            except Exception as e:
                print(f"Submission Request Failed: {e}")
                break